{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022f754b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-27T21:15:52.970289Z",
     "iopub.status.busy": "2023-10-27T21:15:52.969912Z",
     "iopub.status.idle": "2023-10-27T21:15:53.717209Z",
     "shell.execute_reply": "2023-10-27T21:15:53.716299Z"
    },
    "papermill": {
     "duration": 0.756651,
     "end_time": "2023-10-27T21:15:53.719663",
     "exception": false,
     "start_time": "2023-10-27T21:15:52.963012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c4737",
   "metadata": {
    "papermill": {
     "duration": 0.003083,
     "end_time": "2023-10-27T21:15:53.728123",
     "exception": false,
     "start_time": "2023-10-27T21:15:53.725040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75715281",
   "metadata": {
    "papermill": {
     "duration": 0.002936,
     "end_time": "2023-10-27T21:15:53.734274",
     "exception": false,
     "start_time": "2023-10-27T21:15:53.731338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For this task i am required to scrape customer reviews on british airways from <a href='https://www.airlinequality.com'>Skytrax</a>,clean it and analyse the data (sentiment analysis and word clouds were suggested)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3cafe",
   "metadata": {
    "papermill": {
     "duration": 0.003007,
     "end_time": "2023-10-27T21:15:53.740484",
     "exception": false,
     "start_time": "2023-10-27T21:15:53.737477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scraping data from Skytrax\n",
    "We can find customer reviews on the airline<a href='https://www.airlinequality.com/airline-reviews/british-airways'>here</a>.\n",
    "I use beautiful soup to extract it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794833f8",
   "metadata": {
    "papermill": {
     "duration": 0.003151,
     "end_time": "2023-10-27T21:15:53.746798",
     "exception": false,
     "start_time": "2023-10-27T21:15:53.743647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importing libraries............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de885ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T21:15:53.755291Z",
     "iopub.status.busy": "2023-10-27T21:15:53.754425Z",
     "iopub.status.idle": "2023-10-27T21:15:54.001572Z",
     "shell.execute_reply": "2023-10-27T21:15:54.000380Z"
    },
    "papermill": {
     "duration": 0.254175,
     "end_time": "2023-10-27T21:15:54.004115",
     "exception": false,
     "start_time": "2023-10-27T21:15:53.749940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de3ba6",
   "metadata": {
    "papermill": {
     "duration": 0.003161,
     "end_time": "2023-10-27T21:15:54.010795",
     "exception": false,
     "start_time": "2023-10-27T21:15:54.007634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This script extracts 1500 reviews from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c59fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T21:15:54.019373Z",
     "iopub.status.busy": "2023-10-27T21:15:54.018843Z",
     "iopub.status.idle": "2023-10-27T21:16:55.816548Z",
     "shell.execute_reply": "2023-10-27T21:16:55.815308Z"
    },
    "papermill": {
     "duration": 61.80489,
     "end_time": "2023-10-27T21:16:55.818915",
     "exception": false,
     "start_time": "2023-10-27T21:15:54.014025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Currently scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Currently scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Currently scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Currently scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Currently scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Currently scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Currently scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Currently scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Currently scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Currently scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Currently scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Currently scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Currently scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Currently scraping page 15\n",
      "   ---> 1500 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 15 \n",
    "page_size = 100 #How many reviews we intend to scrape per page\n",
    "reviews = [] #list to hold all our reviews\n",
    "\n",
    "\n",
    "max_retries = 7 #How many times we wan't our script to try scrape the data [ poor network problems :( ]\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "    print(f\"Currently scraping page {i}\") #Let's me know my script actually works and how far it's gone\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    retries = 0  # Initialize the retry counter\n",
    "\n",
    "    while retries < max_retries: #retries till it has made 7 attempts\n",
    "        try:\n",
    "            \n",
    "            response = requests.get(url)\n",
    "\n",
    "            # Check if the response status code is 200 (OK)\n",
    "            if response.status_code == 200:\n",
    "        \n",
    "                content = response.content\n",
    "                soup = BeautifulSoup(content, 'html.parser') #Creating the soup that contains all our text\n",
    "\n",
    "                for para in soup.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "                    reviews.append(para.get_text()) #appends the reviews we find into a reviews list\n",
    "\n",
    "                print(f\"   ---> {len(reviews)} total reviews\") #tells me how many reviews i have so far\n",
    "                break  # Exit the retry loop if successful\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error retrieving page {i} - Retry {retries + 1}: {e}\")\n",
    "\n",
    "        # Increment the retry counter\n",
    "        retries += 1 #increases the number of tries\n",
    "\n",
    "    if retries == max_retries: #to let me know my network is terrible or the website has issues\n",
    "        print(f\"Failed to retrieve page {i} after {max_retries} retries.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aebef8",
   "metadata": {
    "papermill": {
     "duration": 0.004107,
     "end_time": "2023-10-27T21:16:55.827460",
     "exception": false,
     "start_time": "2023-10-27T21:16:55.823353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now to load the data into a pandas dataframe............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72d072c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T21:16:55.837857Z",
     "iopub.status.busy": "2023-10-27T21:16:55.837456Z",
     "iopub.status.idle": "2023-10-27T21:16:55.859398Z",
     "shell.execute_reply": "2023-10-27T21:16:55.858625Z"
    },
    "papermill": {
     "duration": 0.029844,
     "end_time": "2023-10-27T21:16:55.861599",
     "exception": false,
     "start_time": "2023-10-27T21:16:55.831755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | First time flying British Ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  I flew London to Cairo and ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Absolutely the worst experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |   Flew back from Malta after sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified | Cabin luggage had to go to carg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0  ✅ Trip Verified | First time flying British Ai...\n",
       "1  Not Verified |  I flew London to Cairo and ret...\n",
       "2  Not Verified |  Absolutely the worst experienc...\n",
       "3  Not Verified |   Flew back from Malta after sc...\n",
       "4  Not Verified | Cabin luggage had to go to carg..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Reviews': reviews})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9ba80",
   "metadata": {
    "papermill": {
     "duration": 0.004321,
     "end_time": "2023-10-27T21:16:55.870731",
     "exception": false,
     "start_time": "2023-10-27T21:16:55.866410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We notice the reviews have verified or not verified before hand, this is uneccesary, so to remove it..........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141c94a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T21:16:55.881856Z",
     "iopub.status.busy": "2023-10-27T21:16:55.880965Z",
     "iopub.status.idle": "2023-10-27T21:16:55.896091Z",
     "shell.execute_reply": "2023-10-27T21:16:55.894985Z"
    },
    "papermill": {
     "duration": 0.02322,
     "end_time": "2023-10-27T21:16:55.898411",
     "exception": false,
     "start_time": "2023-10-27T21:16:55.875191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First time flying British Airways and I would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I flew London to Cairo and return in October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolutely the worst experience ever.  Flew ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew back from Malta after scattering our s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin luggage had to go to cargo, even when I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0   First time flying British Airways and I would...\n",
       "1    I flew London to Cairo and return in October...\n",
       "2    Absolutely the worst experience ever.  Flew ...\n",
       "3     Flew back from Malta after scattering our s...\n",
       "4   Cabin luggage had to go to cargo, even when I..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reviews'] = df['Reviews'].str.split('|',expand=True)[1] \n",
    "#Splits the text in each row and selects the second split only\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1c2d6",
   "metadata": {
    "papermill": {
     "duration": 0.004494,
     "end_time": "2023-10-27T21:16:55.907727",
     "exception": false,
     "start_time": "2023-10-27T21:16:55.903233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "looking good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0564e76",
   "metadata": {
    "papermill": {
     "duration": 0.004525,
     "end_time": "2023-10-27T21:16:55.916925",
     "exception": false,
     "start_time": "2023-10-27T21:16:55.912400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.541875,
   "end_time": "2023-10-27T21:16:56.443439",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-27T21:15:48.901564",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
